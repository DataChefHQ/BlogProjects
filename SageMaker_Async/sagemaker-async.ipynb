{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# IAM role with permissions to create an endpoint, S3 bucket with a preferred prefix\n",
    "role = \"<YOUR_IAM_ROLE>\"\n",
    "bucket = \"<YOUR_BUCKET_NAME>\"\n",
    "prefix = \"<YOUR_FOLDER_NAME>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download California Housing Dataset\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df['Target'] = data['target']\n",
    "\n",
    "# SageMaker XGboost expect the target column to be the first one\n",
    "df = df.loc[:,['Target'] + data['feature_names']]\n",
    "\n",
    "# save as csv with no header row and index column\n",
    "df.to_csv(\"train.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"train.csv\")).upload_file(\"train.csv\")\n",
    "s3_input_train = TrainingInput(s3_data=\"s3://{}/{}\".format(bucket, prefix), content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    silent=0,\n",
    "    num_round=100,\n",
    ")\n",
    "\n",
    "xgb.fit({\"train\": s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Real-Time Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'4.154237747192383'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.predict(\"8.3252,41.0,6.984126984126984,1.0238095238095237,322.0,2.5555555555555554,37.88,-122.23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Async Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# Create an empty AsyncInferenceConfig object to use default values\n",
    "async_config = AsyncInferenceConfig(output_path=f\"s3://{bucket}/{prefix}/output\")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "xgb_async_predictor = xgb.deploy(\n",
    "    async_inference_config=async_config,\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.m4.xlarge', # instance type\n",
    "    serializer=CSVSerializer(), # define serializer to convert bytes to CSV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you can provide the input_path parameter for predict_async with the s3 path for the input data\n",
    "response = xgb_async_predictor.predict_async(\"8.0,41.0,6.9,1.0,322.0,2.5,37.8,-122.2\")\n",
    "output_location = response.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "import boto3\n",
    "\n",
    "def get_output(s3_client, output_path):\n",
    "    output_bucket = output_path.split('/')[2]\n",
    "    output_key = \"/\".join(output_path.split('/')[3:])\n",
    "    while True:\n",
    "        try:\n",
    "            obj = s3_client.Object(output_bucket, output_key)\n",
    "            output = obj.get()['Body'].read().decode('utf-8')\n",
    "            return output\n",
    "        except ClientError as e:\n",
    "            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n",
    "                print(\"waiting for output...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 4.112793445587158\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "output = get_output(s3, output_location)\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_async_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelLatency: 3047 us, RequestDownloadLatency: 18701 us, ResponseUploadLatency: 59713 us, TimeInBacklog: 5 ms, TotalProcessingTime: 94 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
